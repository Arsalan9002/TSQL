USE [tsql-xml-json]


-- getting strctured data out of semi-structured data
SELECT  
    JSON_VALUE(Post_json,'$.Post.Id') as jsonid, -- JSON_VALUE returns single value of type nvarchar(4000)
    JSON_VALUE(Post_json,'$.Post.Title'),
    -- using JSON_QUERY as we need to retrieve object
    JSON_Query(Post_json,'$.Post.Author') as jsonAuthor,  --JSON_QUERY returns json fragment of type nvarchar(max)
    JSON_VALUE(Post_json,'$.Post.Comments[0].Comment.Text') as jsonfirstcolumn

from Posts
where 
-- using JSON_Value to filter on single value in where clause
JSON_VALUE(Post_json,'$.Post.Title') = 'Python vs R for machine learning'

-- select top 10 * from Posts


-- storing data as semi-structured from structured data (FOR JSON)
-- select top 10 * from Comments
SELECT
    Comments.Text as [Comment.Content],
    Users.DisplayName as [Comment.Author.Name],
    Users.LastAccessDate as [Comment.Author.LastAccess],
    JSON_VALUE(post_json,'$.Post.Title') as [Comment.Post]

from Comments 
join Users 
    on Users.Id = Comments.UserId
join Posts 
    on JSON_VALUE(Post_json,'$.Post.Id') = Comments.PostId -- using JSON column like normal column with the help of JSON_VALUE function
WHERE 
    Comments.Score > 15 and 
    JSON_VALUE(Post_json,'$.Post.Title') IS NOT NULL  -- using JSON column for filtering the data

FOR JSON PATH, Root('Comments') -- telling SQL server to create JSON string as per the As clauses defined -- can also define the Root value

--------------------*************************---------------------------
-- THE JSON generated by the above Query will result somehting like this
{
    "Comments": [
        {
            "Comment": {
                "Content": "\"Anything too big to load into Excel\" is the running joke.",
                "Author": {
                    "Name": "Spacedman",
                    "LastAccess": "2019-06-01T12:48:46.740"
                },
                "Post": "How big is big data?"
            }
        },
        {
            "Comment": {
                "Content": "This question might be more appropriate on the dedicated [opendata.SE](http:\/\/opendata.stackexchange.com\/). That said, I cross my fingers for [dat](http:\/\/usodi.org\/2014\/04\/02\/dat), which aspires to become a \"Git for data\".",
                "Author": {
                    "Name": "ojdo",
                    "LastAccess": "2019-05-24T21:03:07.247"
                },
                "Post": "Publicly Available Datasets"
            }
        }
    ]
}
--------------------*************************---------------------------

-- FOR JSON AUTO
SELECT
    Comments.Text,
    Users.DisplayName,
    Users.LastAccessDate,
    JSON_VALUE(post_json,'$.Post.Title') as [CommentsPost]

from Comments 
join Users on Users.Id = Comments.UserId
join Posts on JSON_VALUE(Post_json,'$.Post.Id') = Comments.PostId
WHEre Comments.Score > 15 and JSON_VALUE(Post_json,'$.Post.Title') IS NOT NULL

FOR JSON Auto -- we are asking SQL server to automatically create hierarchy for us

--------------------*************************---------------------------
-- THE [FOR JSON AUTO] results  generated by the above Query 
[
    {
        "Text": "This question might be more appropriate on the dedicated [opendata.SE](http:\/\/opendata.stackexchange.com\/). That said, I cross my fingers for [dat](http:\/\/usodi.org\/2014\/04\/02\/dat), which aspires to become a \"Git for data\".",
        "Users": [
            {
                "DisplayName": "ojdo",
                "LastAccessDate": "2019-05-24T21:03:07.247",
                "CommentsPost": "Publicly Available Datasets"
            }
        ]
    },
    {
        "Text": "\"Anything too big to load into Excel\" is the running joke.",
        "Users": [
            {
                "DisplayName": "Spacedman",
                "LastAccessDate": "2019-06-01T12:48:46.740",
                "CommentsPost": "How big is big data?"
            }
        ]
    }
]
-- it is mendatory for all columns to have names when using FOR JSON function
--------------------*************************---------------------------


--OPENROWSET FOR JSON IMPORT 
DECLARE @JSONFILE VARCHAR(MAX)

select @JSONFILE  = BULKCOLUMN from OPENROWSET (Bulk 'file.json', SINGLE_CLOB) AS j 
-- SINGLE_CLOB tells openrowset to interpret as single column of type varchar(max) 
-- single_blob (binary max), single_nclob (nvarch(max))
PRINT @JSONFILE
if(ISJSON(@JSONFILE)=1) PRINT 'its a valid json' -- validating json structure

--using openjson
DECLARE @JSONFILE VARCHAR (MAX);

SET @JSONFILE = N'[
   {
      "Id":6107,
      "Score":176,
      "ViewCount":155988,
      "Title":"What are deconvolutional layers?",
      "OwnerUserId":8820
   },
   {
      "Id":155,
      "Score":164,
      "ViewCount":25822,
      "Title":"Publicly Available Datasets",
      "OwnerUserId":227
   }
]'; 

SELECT * FROM OPENJSON (@JSONFILE) WITH (
	Id INT, 
	Score INT, 
	ViewCount INT,
	Title VARCHAR(255),
	OwnerUserId INT
) AS TopPosts

--SQL SERVER PROVIDE TWO MODES TO QUERY JSON, LAX & STRICT
SELECT 
    JSON_VALUE(Post_json,'$.Post.Id'),
    JSON_VALUE(Post_json,'$.Post.Title'),
    --using Strict would raise an error if not found. but using lax wont give error it will simply return NULL and lax is the default behavior
    JSON_VALUE(Post_json,'strict$.Post.Badges')  --notice the strict before the path

    from Posts
    where JSON_VALUE(Post_json,'$.Post.Title') LIKE '%python%'




-- loading xml using sp_xml_pareparedocument and process it via openxml function
DECLARE @docHandle int;   -- return handle which will hold xml returned from sp_xml_pareparedocument
DECLARE @xmlDocument nvarchar(max); -- TO hold the XML 

SET @xmlDocument = N'
<ROOT>
<Users Id="227" DisplayName="Amir Ali Akbari" Reputation="805">
    <Posts Title="Publicly Available Datasets" Tags="&lt;open-source&gt;&lt;dataset&gt;">
        <Comments Text="Cross-link: [A database of open databases?](http://opendata.stackexchange.com/questions/266/a-database-of-open-databases)"/>
        <Comments Text="This question might be more appropriate on the dedicated [opendata.SE](http://opendata.stackexchange.com/). That said, I cross my fingers for [dat](http://usodi.org/2014/04/02/dat), which aspires to become a &quot;Git for data&quot;."/>
        <Comments Text="@ojdo Thanks, I never heard of opendata.SE before, I also found [this](http://opendata.stackexchange.com/q/266/2872) interesting (and very similar) question there."/>
        <Comments Text="See http://www.quora.com/Where-can-I-find-large-datasets-open-to-the-public."/>
    </Posts>
</Users>
<Users Id="8820" DisplayName="Martin Thoma" Reputation="6748">
    <Posts Title="What are deconvolutional layers?" Tags="&lt;neural-network&gt;&lt;convnet&gt;&lt;convolution&gt;">
        <Comments Text="Hoping it could be useful to anyone, I made a [notebook](https://gist.github.com/akiross/754c7b87a2af8603da78b46cdaaa5598) to explore how convolution and transposed convolution can be used in TensorFlow (0.11). Maybe having some practical examples and figures may help a bit more to understand how they works."/>
    </Posts>
</Users>
<Users Id="227" DisplayName="Amir Ali Akbari" Reputation="805">
    <Posts Title="Publicly Available Datasets" Tags="&lt;open-source&gt;&lt;dataset&gt;">
        <Comments Text="https://zenodo.org/"/>
        <Comments Text="Reserve Bank of India have a huge database about India,\nWorld Bank have huge data set"/>
        <Comments Text="I havent found any good free comprehensive datasets for typical Business Intelligence applications.  The [Microsoft Contoso BI Demo Dataset for Retail Industry from Official Microsoft Download Center](http://www.microsoft.com/en-us/download/details.aspx?id=18279) download works with some Microsoft products (see [AndyGett on SharePoint and Other Business Software](http://bl
og.bullseyeconsulting.com/archive/2012/08/14/setting-up-sample-contoso-database-for-performancepoint-and-sharepoint.aspx)), but I dont see any plain sql or csv dumps of it, nor any license info."/>
        <Comments Text="A great place to find public data sets is http://opendata.stackexchange.com/"/>
        <Comments Text="Have you joined the Open Data Stack Exchange? http://opendata.stackexchange.com"/>
    </Posts>
</Users>
<Users Id="8820" DisplayName="Martin Thoma" Reputation="6748">
    <Posts Title="What are deconvolutional layers?" Tags="&lt;neural-network&gt;&lt;convnet&gt;&lt;convolution&gt;">
        <Comments Text="This video lecture explains deconvolution/upsampling:\nhttps://youtu.be/ByjaPdWXKJ4?t=16m59s"/>
        <Comments Text="For me, this page gave me a better explanation it also explains the difference between deconvolution and transpose convolution: https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d"/>
        <Comments Text="Isnt upsampling more like backwards pooling than backwards strided convolution, since it has no parameters?"/>
    </Posts>
</Users>
</ROOT>
'
-- @docHandle will hold the xml returned by procedure, its an output parameter and @xmlDocument contains the actual XML that will be loaded by proc
EXEC sp_xml_preparedocument @docHandle OUTPUT, @xmlDocument;

SELECT * FROM 
OPENXML(@docHandle, N'/ROOT/Users/Posts/Comments')  -- specify which nodes are going to be processed as rows
-- spcifying how we are going to return results
WITH (
	Author varchar(255) '../../@DisplayName', -- going two level up from bottom
	Title varchar(500) '../@Title', -- going one level up from bottom
	Tags varchar(500) '../@Tags', -- going one level up from bottom
	Comment varchar(500) '@Text' -- atttibute at the bottom node which is comments node
);

--releasing memory that is currently not in use
EXEC sp_xml_removedocument @docHandle; 

-- USING XML Methods

-- VALUE() AND QUERY METHOD
SELECT 
    -- using value method to get scalar value
	Post_xml.value('(/root/Posts/@Id)[1]', 'int') AS [Post Id],
	Post_xml.value('(/root/Posts/@Title)[1]', 'varchar(500)') AS [Post Title],
	Post_xml.value('(/root/Posts/@CreationDate)[1]', 'datetime') AS [Post Creation],
    -- using query method to retireve nodes
	Post_xml.query('(/root/Posts/Comments)') AS [Post Author]
FROM Posts
WHERE
    --using xml function to filter data 
	Post_xml.value('(/root/Posts/@Score)[1]', 'int') > 100 AND
	Post_xml.value('(/root/Posts/@Title)[1]', 'varchar(500)') IS NOT NULL; 


SELECT 
    Id,
    Post_xml.value('(//Posts/@Title)[1]','nvarchar(255)') as [Post Title],
    -- post & author are not at same level. // allows us to search for Author directly
    Post_xml.value('(//Author/@DisplayName)[1]', 'nvarchar(100)') as [Author],
    Post_xml.query('//Comment[@Score > 2]') as [Relevant Comments]
from Posts

where 
-- Post_xml.value('(//Posts/@Title)[1]','nvarchar(255)') IS NOT NULL
-- ORDER BY Post_xml.value('(//Posts/@Score)[1]','int') DESC -- USE OF VALUE() function in order by clause
---***************************************************---
--Filtering XML data using contains() and exist() method
--Filtering for posts that have comment that has an attribute by the name of tags with the value of machine-learning
Post_xml.exist('//Comment') = 1    -- testing that XML has Comment node
AND Post_xml.exist('(//Posts[contains(@Tags,"machine-learning")])[1]')=1
---***************************************************---



--GETTING rowset view with openxml function

DECLARE @DocHandle int 
DECLARE @XmlDocument nvarchar(1000) 

SET @XmlDocument = N'
<root>
  <Post>
    <Id>22</Id>
    <Title>K-Means clustering for mixed numeric and categorical data</Title>
    <Score>129</Score>
  </Post>
  <Post>
    <Id>155</Id>
    <Title>Publicly Available Datasets</Title>
    <Score>164</Score>
  </Post>
  <Post>
    <Id>694</Id>
    <Title>Best python library for neural networks</Title>
    <Score>131</Score>
  </Post>
  <Post>
    <Id>5706</Id>
    <Title>What is the "dying ReLU" problem in neural networks?</Title>
    <Score>104</Score>
  </Post>
  <Post>
    <Id>6107</Id>
    <Title>What are deconvolutional layers?</Title>
    <Score>176</Score>
  </Post>
  <Post>
    <Id>9302</Id>
    <Title>The cross-entropy error function in neural networks</Title>
    <Score>104</Score>
  </Post>
  <Post>
    <Id>13490</Id>
    <Title>How to set class weights for imbalanced classes in Keras?</Title>
    <Score>109</Score>
  </Post>
</root>'

EXEC sp_xml_preparedocument @DocHandle OUTPUT, @XmlDocument  

-- @docHandle is the OUTPUR PARAMETER obtained from sp_xml_preparedocument procedure
-- second arg is XPATH. all post nodes will be retrieved and will be processed as rows.
SELECT * FROM OPENXML (@DocHandle, '/root/Post',2) 
WITH ( -- with provides rowset format and can effectively be used for schema declaration
	Id int,
	Title nvarchar(100), 
	Score int
) 

-- GETTING rowset view with nodes() function which returns a table
DECLARE @xml xml -- its type is xml since we are using built-in function
SET @xml = N'
<root>
  <Post>
    <Id>22</Id>
    <Title>K-Means clustering for mixed numeric and categorical data</Title>
    <Score>129</Score>
  </Post>
  <Post>
    <Id>155</Id>
    <Title>Publicly Available Datasets</Title>
    <Score>164</Score>
  </Post>
  <Post>
    <Id>694</Id>
    <Title>Best python library for neural networks</Title>
    <Score>131</Score>
  </Post>
  <Post>
    <Id>5706</Id>
    <Title>What is the "dying ReLU" problem in neural networks?</Title>
    <Score>104</Score>
  </Post>
  <Post>
    <Id>6107</Id>
    <Title>What are deconvolutional layers?</Title>
    <Score>176</Score>
  </Post>
  <Post>
    <Id>9302</Id>
    <Title>The cross-entropy error function in neural networks</Title>
    <Score>104</Score>
  </Post>
  <Post>
    <Id>13490</Id>
    <Title>How to set class weights for imbalanced classes in Keras?</Title>
    <Score>109</Score>
  </Post>
</root>'

-- modify the XML type variable or column  starts here
SELECT @xml
-- replace value of part of XML DML and is equivalent to DML statement
set @xml.modify('
    replace value of (/root/Post/Title/text())[2]
    with "This is updated by Arsalan Mehmood"
');

SELECT @xml

-- modify the XML type variable or column  ends here

SELECT
	doc.col.value('Id[1]', 'int') id,
	doc.col.value('Title[1]', 'nvarchar(100)') title,
	doc.col.value('Score[1]', 'int') score 
    -- nodes method takes XQUERY as expressions to figure out which nodes should be processed as rows
    --doc(col) corresponds to table and column name for resulting row set
    -- we are using doc.col above to extract the data from the table returned by nodes() function
FROM @xml.nodes('/root/Post') doc(col)  




--Temporal Tables
CREATE TABLE PostsTemporal (
	Id INT NOT NULL PRIMARY KEY CLUSTERED,
	CreationDate DATETIME NOT NULL DEFAULT GETDATE(),
	Score INT NOT NULL DEFAULT 0,
	ViewCount INT,
	Body VARCHAR(MAX) NOT NULL,
	OwnerUserId INT,
	LastActivityDate DATETIME NOT NULL DEFAULT GETDATE(),
	Title VARCHAR(500),
	Tags VARCHAR(255),
	AnswerCount INT,
	CommentCount INT,
	FavoriteCount INT,

    --PERIOD COLUMNS
    SysStartTime datetime2 GENERATED ALWAYS AS ROW START NOT NULL,
    SysEndTime datetime2 GENERATED ALWAYS AS ROW END NOT NULL,
    --specifying the period columns
    PERIOD FOR SYSTEM_TIME (SysStartTime,SysEndTime)
)
-- Defined the table which is going to store the history
WITH (SYSTEM_VERSIONING  = ON (HISTORY_TABLE = dbo.PostHistory))

--Inserting multiple data rows into temporal table
INSERT INTO PostsTemporal(
    Id, CreationDate, ViewCount,Body, OwnerUserId,LastActivityDate,title,tags, AnswerCount,CommentCount,FavoriteCount)

SELECT
    Id,
    JSON_VALUE(post_json,'$.Post.CreationDate') as CreationDate,
    JSON_VALUE(post_json,'$.Post.Score') as Score,
    JSON_VALUE(post_json,'$.Post.ViewCount') as ViewCount,
    JSON_VALUE(post_json,'$.Post.OwnerUserId') as OwnerUserId,
    JSON_VALUE(post_json,'$.Post.LastActivityDate') as LastActivityDate,
    JSON_VALUE(post_json,'$.Post.Title') as Title,
    JSON_VALUE(post_json,'$.Post.Tags') as Tags,
    JSON_VALUE(post_json,'$.Post.AnswerCount') as AnswerCount,
    JSON_VALUE(post_json,'$.Post.CommentCount') as CommentCount,
    JSON_VALUE(post_json,'$.Post.FavoriteCount') as FavoriteCount

from Posts
where
    JSON_VALUE(post_json,'$.Post.Tags')  like '%Python%' and 
    JSON_VALUE(post_json,'$.Post.Score') > 20  and 
    JSON_VALUE(post_json,'$.Post.Body') IS NOT NULL

--selecting data from both table, we will see data in temporal table but history table would be Empty Initially
SELECT * FROM PostsTemporal
select * from PostHistory


--modification data rows in the temporal table
UPDATE PostsTemporal 
	SET Title = 'Estimating users age based on Facebook sites they like'
	WHERE Id = 116;

UPDATE PostsTemporal 
	SET Title = 'Which cost function is the best option for neural networks'
	WHERE Id = 9850;

-- selecting data again after modification in temporal table
SELECT * FROM PostsTemporal
select * from PostHistory -- now we will see 2 records in history table


UPDATE PostsTemporal
	SET Score += 50
	WHERE Tags LIKE '%neural-network%' OR Tags LIKE '%deep-learning%';


SELECT * FROM PostsTemporal;
SELECT * FROM PostHistory;


--deleting data from temporal table
DELETE PostsTemporal 
	WHERE Score < 50;


SELECT * FROM PostsTemporal;
SELECT * FROM PostHistory;



--selecting data from temporal table
select  * from 
PostsTemporal WHERE Id= 9850; -- This record exist in history table as well as we modified above

--selecting its state specific time 
select  Id,Score, Title, CreationDate, OwnerUserId from 
PostsTemporal 
for SYSTEM_TIME AS OF '2020-05-04 05:56:27'
WHERE Id= 9850;

-- we can query temporal table using system_time or we can also query history table directly
-- retrieve the deleted record
select * from PostsTemporal where Id= 116 -- zero rows because we deleted this record

-- retriving its state at speicifc time interval
select * from PostsTemporal 
for SYSTEM_TIME as of '2020-05-04 05:58:36'
where Id= 116

-- querying history table for deleted record
SELECT * FROM PostHistory WHERE Id=116



-- RETIREVING all the changes that have occurred to a particular record in the order in which they occurred
select * from PostsTemporal for system_time ALL  where id=9850 order by SysEndTime



--Recovering data in temporal tables
select * from PostsTemporal where Tags like '%python%'

delete from PostsTemporal where Tags like '%python%'

select * from PostHistory where id=492 -- 492,694

insert into PostsTemporal(
    Id, CreationDate, ViewCount,Body, OwnerUserId,LastActivityDate,title,tags, AnswerCount,CommentCount,FavoriteCount)
select Id, CreationDate, ViewCount,Body, OwnerUserId,LastActivityDate,title,tags, AnswerCount,CommentCount,FavoriteCount
    from PostsTemporal for system_time AS OF '2020-05-04 06:44:08'

